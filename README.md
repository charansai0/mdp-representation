# MDP REPRESENTATION

## AIM:
Write your aim here

## PROBLEM STATEMENT:

### Problem Description
Write your answer here

### State Space
Write your answer here

### Sample State
Write your answer here

### Action Space
Write your answer here

### Sample Action
Write your answer here

### Reward Function
Write your answer here

### Graphical Representation
Write your answer here

## PYTHON REPRESENTATION:
~~~

P = {
    0:{
        0: [(0.55,0,0,True),(0.13,1,0,False)],
        1: [(0.13,1,0,False),(0.55,0,0,True)]
    },
    1:{
        0: [(0.55,1,0,False),(0.13,2,1,True)],
        1: [(0.13,2,1,True),(0.55,1,0,False)]
    },
    2:{
        0: [(0.55,2,1,True),(0.13,1,1,False)],
        1: [(0.13,1,1,False),(0.55,2,1,True)]
    }
}


~~~

## OUTPUT:
![image](https://github.com/charansai0/mdp-representation/assets/94296221/7e09d35a-aa50-4b86-85c1-9f9ea7e0bb3c)


## RESULT:
Therefore an MDP representation has been created for a real world scenario with all the states, actions and rewards.
